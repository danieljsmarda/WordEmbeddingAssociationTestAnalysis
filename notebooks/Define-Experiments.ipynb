{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import filter_terms_not_in_wemodel, save_pickle, open_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done!\n",
      "Total words: 2196016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Miniconda3\\envs\\semproject2\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "glove_file = '../data/external/glove.840B.300d/glove.840B.300d.txt'\n",
    "#_ = glove2word2vec(glove_file, '../data/interim/glove_840_tmp.txt')\n",
    "we_model = KeyedVectors.load_word2vec_format('../data/interim/glove_840_tmp.txt')\n",
    "print('loading done!')\n",
    "print(f'Total words: {len(we_model.wv.vocab)}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "we_model_name = \"sg_dim300_min100_win5\"\n",
    "we_vector_size = 300\n",
    "we_model_dir = '../data/external/wiki-english/wiki-english-20171001/%s' % we_model_name\n",
    "\n",
    "we_model = Word2Vec.load(we_model_dir+'/model.gensim')\n",
    "print ('loading done!')\n",
    "print(f'Total words: {len(we_model.wv.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "we_model.init_sims(replace=True)\n",
    "we_model.save('../data/interim/glove_840_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_model_load = KeyedVectors.load('../data/interim/glove_840_norm', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/glove_840B_experiment_definitions.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, X_label, Y_label, A_label, B_label, filepath):\n",
    "    dct = open_pickle(filepath)\n",
    "    dct[exp_num]['X_terms'] = X_terms\n",
    "    dct[exp_num]['Y_terms'] = Y_terms\n",
    "    dct[exp_num]['A_terms'] = A_terms\n",
    "    dct[exp_num]['B_terms'] = B_terms\n",
    "    dct[exp_num]['X_label'] = X_label\n",
    "    dct[exp_num]['Y_label'] = Y_label\n",
    "    dct[exp_num]['A_label'] = A_label\n",
    "    dct[exp_num]['B_label'] = B_label\n",
    "    save_pickle(dct, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This cell for structure\n",
    "# WEAT 1\n",
    "exp_num = 1\n",
    "X_label = 'Flowers'\n",
    "Y_label = 'Insects'\n",
    "A_label = 'Pleasant'\n",
    "B_label = 'Unpleasant'\n",
    "X_terms = ['aster', 'clover', 'hyacinth', 'marigold', 'poppy', 'azalea', \n",
    "           'crocus', 'iris', 'orchid', 'rose', 'bluebell', 'daffodil','lilac',\n",
    "           'pansy','tulip','buttercup','daisy','lily','penny','violet','carnation', 'gladiola',\n",
    "           'magnolia','petunia','zinnia']\n",
    "Y_terms = ['ant','caterpillar','flea','locust','spider','bedbug','centipede','fly',\n",
    "          'maggot','tarantula','bee','cockroach','gnat','mosquito','termite','beetle',\n",
    "          'cricket','hornet','moth','wasp','blackfly','dragonfly','horsefly','roach',\n",
    "          'weevil']\n",
    "A_terms = ['caress','freedom','health','love','peace','cheer','friend','heaven',\n",
    "           'loyal','pleasure','diamond','gentle','honest','lucky','rainbow','diploma',\n",
    "           'gift','honor','miracle','sunrise','family','happy','laugher','paradise',\n",
    "           'vacation']\n",
    "B_terms = ['abuse','crash','filth','murder','sickness','accident','death','grief',\n",
    "          'poison','stink','assault','disaster','hatred','pollute','tragedy',\n",
    "          'divorce','jail','poverty','ugly','cancer','kill','rotten','vomit','agony',\n",
    "          'prison']\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the second list to balance the length of the lists: ['arrow']\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the first list to balance the length of the lists: ['Brad']\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n"
     ]
    }
   ],
   "source": [
    "# WEAT 1\n",
    "exp_num = 1\n",
    "X_label = 'Flowers'\n",
    "Y_label = 'Insects'\n",
    "A_label = 'Pleasant'\n",
    "B_label = 'Unpleasant'\n",
    "X_terms = ['aster', 'clover', 'hyacinth', 'marigold', 'poppy', 'azalea', \n",
    "           'crocus', 'iris', 'orchid', 'rose', 'bluebell', 'daffodil','lilac',\n",
    "           'pansy','tulip','buttercup','daisy','lily','penny','violet','carnation', 'gladiola',\n",
    "           'magnolia','petunia','zinnia']\n",
    "Y_terms = ['ant','caterpillar','flea','locust','spider','bedbug','centipede','fly',\n",
    "          'maggot','tarantula','bee','cockroach','gnat','mosquito','termite','beetle',\n",
    "          'cricket','hornet','moth','wasp','blackfly','dragonfly','horsefly','roach',\n",
    "          'weevil']\n",
    "A_terms = ['caress','freedom','health','love','peace','cheer','friend','heaven',\n",
    "           'loyal','pleasure','diamond','gentle','honest','lucky','rainbow','diploma',\n",
    "           'gift','honor','miracle','sunrise','family','happy','laugher','paradise',\n",
    "           'vacation']\n",
    "B_terms = ['abuse','crash','filth','murder','sickness','accident','death','grief',\n",
    "          'poison','stink','assault','disaster','hatred','pollute','tragedy',\n",
    "          'divorce','jail','poverty','ugly','cancer','kill','rotten','vomit','agony',\n",
    "          'prison']\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)\n",
    "\n",
    "# WEAT 2\n",
    "exp_num = 2\n",
    "X_label = 'Instruments'\n",
    "Y_label = 'Weapons'\n",
    "A_label = 'Pleasant'\n",
    "B_label = 'Unpleasant'\n",
    "X_terms = ['bagpipe','cello','guitar','lute','trombone','banjo','clarinet','harmonica',\n",
    "           'mandolin','trumpet','bassoon','drum','harp','oboe','tuba','bell','fiddle',\n",
    "           'harpsichord','piano','viola','bongo','flute','horn','saxophone']\n",
    "Y_terms = ['arrow','club','gun','missile','spear','axe','dagger','harpoon','pistol',\n",
    "          'sword','blade','dynamite','hatchet','rifle','tank','bomb','firearm',\n",
    "          'knife','shotgun','teargas','cannon','grenade','mace','slingshot','whip']\n",
    "A_terms = ['caress','freedom','health','love','peace','cheer','friend','heaven',\n",
    "           'loyal','pleasure','diamond','gentle','honest','lucky','rainbow','diploma',\n",
    "           'gift','honor','miracle','sunrise','family','happy','laugher','paradise',\n",
    "           'vacation']\n",
    "B_terms = ['abuse','crash','filth','murder','sickness','accident','death','grief',\n",
    "          'poison','stink','assault','disaster','hatred','pollute','tragedy',\n",
    "          'divorce','jail','poverty','ugly','cancer','kill','rotten','vomit','agony',\n",
    "          'prison']\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)\n",
    "\n",
    "\n",
    "# WEAT 3\n",
    "exp_num = 3\n",
    "X_label = 'Eur-Am Names'\n",
    "Y_label = 'Afr-Am Names'\n",
    "A_label = 'Pleasant'\n",
    "B_label = 'Unpleasant'\n",
    "X_terms = ['adam', 'chip', 'harry', 'josh','roger','alan','frank','ian', 'justin',\n",
    "          'ryan','andrew','fred','jack','matthew','stephen','brad','greg','jed',\n",
    "          'paul','todd','brandon','hank','jonathan','peter','wilbur','amanda',\n",
    "          'courtney','heather','melanie','sara','amber','crystal','katie',\n",
    "          'meredith','shannon','betsy','donna','kristin','nancy','stephanie',\n",
    "          'Bobbie-Sue','ellen','lauren','peggy','Sue-Ellen','colleen','emily',\n",
    "          'megan','rachel','wendy']\n",
    "X_italics = ['chip', 'ian', 'fred', 'jed', 'todd', 'brandon', 'hank',\n",
    "            'wilbur', 'sara', 'amber', 'crystal', 'meredith', 'shannon', 'donna',\n",
    "            'Bobbie-Sue', 'peggy', 'Sue-Ellen', 'wendy']\n",
    "Y_terms = ['alonzo','jamel','lerone', 'percell', 'theo','alphonse','jerome','leroy',\n",
    "           'rasaan', 'torrance','darnell','lamar','lionel','rashaun','tyree','deion',\n",
    "          'lamont','malik','terrence','tyrone','everol', 'lavon', 'marcellus', 'terryl',\n",
    "          'wardell','aiesha','lashelle','nichelle','shereen','temeka','ebony',\n",
    "          'latisha','shaniqua','tameisha','teretha','jasmine','latonya','shanise',\n",
    "          'tanisha','tia','lakisha','latoya','sharise','tashika','yolanda',\n",
    "          'lashandra','malika','shavonn','tawanda','yvette']\n",
    "Y_italics = ['lerone', 'percell', 'rasaan', 'rashaun', 'everol', 'terryl','aiesha',\n",
    "            'lashelle', 'temeka', 'tameisha', 'teretha', 'latonya', 'shanise',\n",
    "            'sharise', 'tashika', 'lashandra', 'shavonn', 'tawanda']\n",
    "A_terms = ['caress','freedom','health','love','peace','cheer','friend','heaven',\n",
    "          'loyal','pleasure','diamond','gentle','honest','lucky','rainbow',\n",
    "          'diploma','gift','honor','miracle','sunrise','family','happy','laughter',\n",
    "          'paradise','vacation']\n",
    "B_terms = ['abuse','crash','filth','murder','sickness','accident','death','grief',\n",
    "          'poison','stink','assault','disaster','hatred','pollute','tragedy','bomb',\n",
    "          'divorce','jail','poverty','ugly','cancer','evil','kill','rotten','vomit']\n",
    "X_terms = [s.capitalize() for s in X_terms if s not in X_italics]\n",
    "Y_terms = [s.capitalize() for s in Y_terms if s not in Y_italics]\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)\n",
    "\n",
    "# WEAT 4\n",
    "exp_num = 4\n",
    "X_label = 'Eur-Am Names'\n",
    "Y_label = 'Afr-Am Names'\n",
    "A_label = 'Pleasant'\n",
    "B_label = 'Unpleasant'\n",
    "X_terms = ['brad', 'brendan', 'geoffrey', 'greg', 'brett', 'jay', 'matthew', 'neil', \n",
    "            'todd', 'allison', 'anne', 'carrie', 'emily', 'jill', 'laurie', 'kristen',\n",
    "            'meredith', 'sarah']\n",
    "X_italics = ['jay','kristen']\n",
    "Y_terms = ['darnell', 'hakim', 'jermaine', 'kareem', 'jamal', 'leroy', 'rasheed',\n",
    "        'tremayne', 'tyrone', 'aisha', 'ebony', 'keisha', 'kenya', 'latonya', \n",
    "        'lakisha', 'latoya', 'tamika', 'tanisha']\n",
    "Y_italics = ['tremayne', 'latonya']\n",
    "A_terms = ['caress','freedom','health','love','peace','cheer','friend','heaven',\n",
    "           'loyal','pleasure','diamond','gentle','honest','lucky','rainbow','diploma',\n",
    "           'gift','honor','miracle','sunrise','family','happy','laugher','paradise',\n",
    "           'vacation']\n",
    "B_terms = ['abuse','crash','filth','murder','sickness','accident','death','grief',\n",
    "          'poison','stink','assault','disaster','hatred','pollute','tragedy',\n",
    "          'bomb','divorce','jail','poverty','ugly','cancer','evil','kill',\n",
    "          'rotten','vomit']\n",
    "X_terms = [s.capitalize() for s in X_terms if s not in X_italics]\n",
    "Y_terms = [s.capitalize() for s in Y_terms if s not in Y_italics]\n",
    "#[X_terms, Y_terms, A_tersm, B_terms] = [[str.lower(term) for term in terms] for terms in [X_terms, Y_terms, A_terms, B_terms]]\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)\n",
    "\n",
    "\n",
    "# WEAT 5\n",
    "exp_num = 5\n",
    "X_label = 'Eur-Am Names'\n",
    "Y_label = 'Afr-Am Names'\n",
    "A_label = 'Pleasant'\n",
    "B_label = 'Unpleasant'\n",
    "X_terms = ['brad', 'brendan', 'geoffrey', 'greg', 'brett', 'jay', 'matthew',\n",
    "            'neil', 'todd', 'allison', 'anne', 'carrie', 'emily', 'jill',\n",
    "            'laurie', 'kristen', 'meredith', 'sarah']\n",
    "X_italics = ['jay','kristen']\n",
    "Y_terms = ['darnell', 'hakim', 'jermaine', 'kareem', 'jamal', 'leroy', 'rasheed',\n",
    "        'tremayne', 'tyrone', 'aisha', 'ebony', 'keisha', 'kenya', 'latonya',\n",
    "        'latoya', 'tamika', 'tanisha']\n",
    "Y_italics = ['tremayne', 'latonya']\n",
    "A_terms = ['joy', 'love', 'peace', 'wonderful', 'pleasure', 'friend', 'laughter', 'happy']\n",
    "B_terms = ['agony', 'terrible', 'horrible', 'nasty', 'evil', 'war', 'awful', 'failure']\n",
    "X_terms = [s.capitalize() for s in X_terms if s not in X_italics]\n",
    "Y_terms = [s.capitalize() for s in Y_terms if s not in Y_italics]\n",
    "#[X_terms, Y_terms, A_tersm, B_terms] = [[str.lower(term) for term in terms] for terms in [X_terms, Y_terms, A_terms, B_terms]]\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)\n",
    "\n",
    "# WEAT 6\n",
    "exp_num = 6\n",
    "X_label = 'Male Names'\n",
    "Y_label = 'Female Names'\n",
    "A_label = 'Career'\n",
    "B_label = 'Family'\n",
    "X_terms = ['john', 'paul','mike','kevin','steve','greg','jeff','bill']\n",
    "Y_terms = ['amy','joan','lisa','sarah','diana','kate','ann','donna']\n",
    "A_terms = ['executive','management','professional','corporation',\n",
    "               'salary','office','business','career']\n",
    "B_terms = ['home','parents','children','family',\n",
    "               'cousins','marriage','wedding','relatives']\n",
    "\n",
    "X_terms = [s.capitalize() for s in X_terms if s not in X_italics]\n",
    "Y_terms = [s.capitalize() for s in Y_terms if s not in Y_italics]\n",
    "#[X_terms, Y_terms, A_tersm, B_terms] = [[str.lower(term) for term in terms] for terms in [X_terms, Y_terms, A_terms, B_terms]]\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)\n",
    "\n",
    "\n",
    "# WEAT 7\n",
    "exp_num = 7\n",
    "X_label = 'Math'\n",
    "Y_label = 'Arts'\n",
    "A_label = 'Male Terms'\n",
    "B_label = 'Female Terms'\n",
    "X_terms = ['math','algebra','geometry','calculus',\n",
    "             'equations','computation','numbers','addition']\n",
    "Y_terms = ['poetry','art','dance','literature',\n",
    "             'novel','symphony','drama','sculpture']\n",
    "A_terms = ['male','man','boy','brother',\n",
    "              'he','him','his','son']\n",
    "B_terms = ['female','woman','girl','sister',\n",
    "               'she','her','hers','daughter']\n",
    "[X_terms, Y_terms, A_tersm, B_terms] = [[str.lower(term) for term in terms] for terms in [X_terms, Y_terms, A_terms, B_terms]]\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)\n",
    "\n",
    "# Weat 8\n",
    "exp_num = 8\n",
    "X_label = 'Science'\n",
    "Y_label = 'Arts'\n",
    "A_label = 'Male Terms'\n",
    "B_label = 'Female Terms'\n",
    "X_terms = ['science','technology','physics','chemistry',\n",
    "          'Einstein','NASA','experiment','astronomy']\n",
    "Y_terms = ['poetry','art','Shakespeare','dance',\n",
    "          'literature','novel','symphony','drama']\n",
    "A_terms = ['brother','father','uncle','grandfather',\n",
    "          'son','he','his','him']\n",
    "B_terms = ['sister','mother','aunt','grandmother',\n",
    "          'daughter','she','hers','her']\n",
    "[X_terms, Y_terms, A_tersm, B_terms] = [[str.lower(term) for term in terms] for terms in [X_terms, Y_terms, A_terms, B_terms]]\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)\n",
    "\n",
    "\n",
    "# WEAT 9\n",
    "exp_num = 9\n",
    "X_label = 'Mental Disease'\n",
    "Y_label = 'Physical Disease'\n",
    "A_label = 'Temporary'\n",
    "B_label = 'Permanent'\n",
    "X_terms = ['sad','hopeless','gloomy','tearful','miserable','depressed']\n",
    "Y_terms = ['sick','illness','influenza','disease','virus','cancer']\n",
    "A_terms = ['impermanent','unstable','variable','fleeting','short','brief',\n",
    "          'occasional']\n",
    "B_terms = ['stable','always','constant','persistent','chronic','prolonged','forever']\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)\n",
    "\n",
    "# Weat 10\n",
    "exp_num = 10\n",
    "X_label = 'Young Names'\n",
    "Y_label = 'Old Names'\n",
    "A_label = 'Pleasant'\n",
    "B_label = 'Unpleasant'\n",
    "X_terms = ['Tiffany', 'Michelle', 'Cindy', 'Kristy', 'Brad', 'Eric', 'Joey', 'Billy']\n",
    "Y_terms = ['Ethel', 'Bernice', 'Gertrude', 'Agnes', 'Cecil', 'Wilbert', 'Mortimer', 'Edgar']\n",
    "A_terms = ['joy', 'love', 'peace', 'wonderful', 'pleasure', 'friend', 'laughter', 'happy']\n",
    "B_terms = ['agony', 'terrible', 'horrible', 'nasty', 'evil', 'war', 'awful', 'failure']\n",
    "[X_terms, Y_terms, A_tersm, B_terms] = [[str.lower(term) for term in terms] for terms in [X_terms, Y_terms, A_terms, B_terms]]\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
