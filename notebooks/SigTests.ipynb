{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import random\n",
    "random.seed(5)\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import get_matrices_from_term_lists, \\\n",
    "    save_pickle, open_pickle, \\\n",
    "    save_experiment_arbitrary_label, \\\n",
    "    del_dict_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'glove_840B'\n",
    "RESULTS_FILEPATH = f'../data/interim/{MODEL_NAME}_association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = f'../data/interim/{MODEL_NAME}_experiment_definitions.pickle'\n",
    "we_model = KeyedVectors.load(f'../data/interim/{MODEL_NAME}_norm', mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastest version, 10000 words -> 1 minute\n",
    "# (Possible TODO) May be able to add minimal speedup with itemgetter \n",
    "# (see https://stackoverflow.com/questions/18453566/python-dictionary-get-list-of-values-for-list-of-keys)\n",
    "# to speed up creation of word matrices in get_matrices_from_term_lists\n",
    "def get_test_stat(wv_obj, X_terms, Y_terms, A_terms, B_terms):  \n",
    "    [X_mtx, Y_mtx, A_mtx, B_mtx] = get_matrices_from_term_lists(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "    cosine_sim_XA = cosine_similarity(X_mtx, A_mtx)\n",
    "    cosine_sim_XB = cosine_similarity(X_mtx, B_mtx)\n",
    "    mean_over_Xa = np.mean(cosine_sim_XA, axis=1)\n",
    "    mean_over_Xb = np.mean(cosine_sim_XB, axis=1)\n",
    "    s_for_X_words = mean_over_Xa - mean_over_Xb\n",
    "    # shape is (24,) or (|X_terms|,)\n",
    "\n",
    "    cosine_sim_YA = cosine_similarity(Y_mtx, A_mtx)\n",
    "    cosine_sim_YB = cosine_similarity(Y_mtx, B_mtx)\n",
    "    mean_over_Ya = np.mean(cosine_sim_YA, axis=1)\n",
    "    mean_over_Yb = np.mean(cosine_sim_YB, axis=1)\n",
    "    s_for_Y_words = mean_over_Ya - mean_over_Yb\n",
    "    test_stat = np.mean(s_for_X_words) - np.mean(s_for_Y_words)\n",
    "    return test_stat\n",
    "#get_test_stat(we_model, X_terms, Y_terms, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in tqdm(range(10000)):\\n    [X_mtx, Y_mtx, A_mtx, B_mtx] = get_matrices_from_term_lists(we_model, X_terms, Y_terms, A_terms, B_terms)\\n    X_associations = np.apply_along_axis(lambda x_vec: calculate_association_metric_for_target_word(x_vec, A_mtx, B_mtx), 1, X_mtx)\\n    Y_associations = np.apply_along_axis(lambda y_vec: calculate_association_metric_for_target_word(y_vec, A_mtx, B_mtx), 1, Y_mtx)\\n    m = np.mean(X_associations) - np.mean(Y_associations)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell works too. It takes twice as long as the cell above,\n",
    "# but if we want to try to vectorize the outer loop, then \n",
    "# we will probably have to use this version\n",
    "def calculate_association_metric_for_target_word(word_vec, A_mtx, B_mtx):\n",
    "    '''Computes the association metric, s(w,A,B).\n",
    "    word_vec: 1-D word vector\n",
    "    A_mtx, B_mtx: 2-D word vector arrays'''\n",
    "    A_dot_v = np.dot(A_mtx, word_vec)\n",
    "    B_dot_v = np.dot(B_mtx, word_vec)\n",
    "    A_norms = np.multiply(np.linalg.norm(A_mtx, axis=1), np.linalg.norm(word_vec))\n",
    "    B_norms = np.multiply(np.linalg.norm(B_mtx, axis=1), np.linalg.norm(word_vec))\n",
    "    A_cosines = np.divide(A_dot_v, A_norms)\n",
    "    B_cosines = np.divide(B_dot_v, B_norms)\n",
    "    return np.mean(A_cosines) - np.mean(B_cosines)\n",
    "\n",
    "'''\n",
    "for i in tqdm(range(10000)):\n",
    "    [X_mtx, Y_mtx, A_mtx, B_mtx] = get_matrices_from_term_lists(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "    X_associations = np.apply_along_axis(lambda x_vec: calculate_association_metric_for_target_word(x_vec, A_mtx, B_mtx), 1, X_mtx)\n",
    "    Y_associations = np.apply_along_axis(lambda y_vec: calculate_association_metric_for_target_word(y_vec, A_mtx, B_mtx), 1, Y_mtx)\n",
    "    m = np.mean(X_associations) - np.mean(Y_associations)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_test_stats(wv_obj, X_terms, Y_terms, A_terms, B_terms, n_samples=100):\n",
    "    sigtest_dist_1 = []\n",
    "    sigtest_dist_2 = []\n",
    "    sigtest_dist_3 = []\n",
    "    n_targets = len(X_terms)\n",
    "    n_attributes = len(A_terms)\n",
    "    assert len(X_terms) == len(Y_terms)\n",
    "    assert len(A_terms) == len(B_terms)\n",
    "    vocab_list = list(wv_obj.vocab)\n",
    "    random.seed(5)\n",
    "    for i in tqdm(range(n_samples), desc=f'Calculating SigTest values for {n_samples} samples'):\n",
    "        X_sample = random.sample(vocab_list, k=n_targets)\n",
    "        Y_sample = random.sample(vocab_list, k=n_targets)\n",
    "        sigtest_dist_1.append(get_test_stat(wv_obj, X_sample, Y_sample, A_terms, B_terms))\n",
    "        sigtest_dist_2.append(get_test_stat(wv_obj, X_terms, Y_sample, A_terms, B_terms))\n",
    "        sigtest_dist_3.append(get_test_stat(wv_obj, Y_terms, X_sample, A_terms, B_terms))\n",
    "        #sigtest_dist_3.append(get_test_stat(wv_obj, X_sample, Y_terms, A_terms, B_terms))\n",
    "    return np.array(sigtest_dist_1), np.array(sigtest_dist_2), np.array(sigtest_dist_3)\n",
    "#a,b,c = get_n_test_stats(we_model, X_terms, Y_terms, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating SigTest values for samples:   0%|                                                  | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Experiment: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating SigTest values for samples: 100%|████████████████████████████████████████| 100/100 [00:02<00:00, 36.28it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'order' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-1c21adf4bfe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         save_experiment_arbitrary_label(RESULTS_FILEPATH, exp_num, order,\n\u001b[0;32m     20\u001b[0m                                         'sigtest_dist_3', dist_3)\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mrun_all_sigtests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-1c21adf4bfe1>\u001b[0m in \u001b[0;36mrun_all_sigtests\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mcomparison_statistic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mdist_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_n_test_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         save_experiment_arbitrary_label(RESULTS_FILEPATH, exp_num, order,\n\u001b[0m\u001b[0;32m     16\u001b[0m                                         'sigtest_dist_1', dist_1)\n\u001b[0;32m     17\u001b[0m         save_experiment_arbitrary_label(RESULTS_FILEPATH, exp_num, order,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'order' is not defined"
     ]
    }
   ],
   "source": [
    "# Reminder that if you run this cell with a lower number of n_samples, \n",
    "# It will overwrite what's currently in the dictionary\n",
    "def run_all_sigtests(new_dists=False, n_samples=100):\n",
    "    #TODO: refactor: remove 'order' argument, no longer necessary\n",
    "    exps = open_pickle(EXPERIMENT_DEFINITION_PATH)\n",
    "    for exp_num, exp in exps.items():\n",
    "        print('******************************')\n",
    "        print(f'Experiment: {exp_num}')\n",
    "        X_terms = exp['X_terms']\n",
    "        Y_terms = exp['Y_terms']\n",
    "        A_terms = exp['A_terms']\n",
    "        B_terms = exp['B_terms']\n",
    "        \n",
    "        comparison_statistic = get_test_stat(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "        if new_dists:\n",
    "            dist_1, dist_2, dist_3 = get_n_test_stats(we_model, X_terms, Y_terms, A_terms, B_terms, n_samples=n_samples)\n",
    "        else:\n",
    "            dist_1, dist_2, dist_3 = [results_dict[exp_num][order][f'sigtest_dist_{n}'] for n in [1,2,3]]\n",
    "        p_value = norm.cdf(comparison_statistic, loc=np.mean(dist_1), scale=np.std(dist_1))\n",
    "  \n",
    "        save_experiment_arbitrary_label(RESULTS_FILEPATH, exp_num, order,\n",
    "                                        'sigtest_dist_1', dist_1)\n",
    "        save_experiment_arbitrary_label(RESULTS_FILEPATH, exp_num, order,\n",
    "                                        'sigtest_dist_2', dist_2)\n",
    "        save_experiment_arbitrary_label(RESULTS_FILEPATH, exp_num, order,\n",
    "                                        'sigtest_dist_3', dist_3)\n",
    "        save_experiment_arbitrary_label(RESULTS_FILEPATH, exp_num, order,\n",
    "                                        'test_statistic', comparison_statistic)\n",
    "        save_experiment_arbitrary_label(RESULTS_FILEPATH, exp_num, order,\n",
    "                                        'ST1_p-value', p_value)\n",
    "\n",
    "run_all_sigtests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER = second\n",
      "******************************\n",
      "Experiment: 1\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [1][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [1][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 2\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [2][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [2][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 3\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [3][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [3][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 4\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [4][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [4][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 5\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [5][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [5][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 6\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [6][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [6][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 7\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [7][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [7][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 8\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [8][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [8][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 9\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [9][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [9][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 10\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [10][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [10][second][ST1_p-value]\n"
     ]
    }
   ],
   "source": [
    "def calculate_all_sigtest_metrics():\n",
    "    exps = open_pickle(EXPERIMENT_DEFINITION_PATH)\n",
    "    results_dict = open_pickle(RESULTS_FILEPATH)\n",
    "    for exp_num, exp in exps.items():\n",
    "        print('******************************')\n",
    "        print(f'Experiment: {exp_num}')\n",
    "        X_terms = exp['X_terms']\n",
    "        Y_terms = exp['Y_terms']\n",
    "        A_terms = exp['A_terms']\n",
    "        B_terms = exp['B_terms']\n",
    "        comparison_statistic = get_test_stat(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "\n",
    "        dist_1, dist_2, dist_3 = [results_dict[exp_num][order][f'sigtest_dist_{n}'] for n in [1,2,3]]\n",
    "        loc_1, loc_2, loc_3 = [np.mean(dist) for dist in [dist_1, dist_2, dist_3]]\n",
    "        scale_1, scale_2, scale_3 = [np.std(dist) for dist in [dist_1, dist_2, dist_3]]\n",
    "        # If you want to play around with statistics of the distributions,\n",
    "        # Add code and print statements here, e.g.\n",
    "        # print(f'90% CI for dist 1: {norm.ppf(0.1, loc=loc_1, scale=scale_1)}')\n",
    "\n",
    "        save_experiment_arbitrary_label(RESULTS_FILEPATH, exp_num, order, 'test_statistic', comparison_statistic)\n",
    "        save_experiment_arbitrary_label(RESULTS_FILEPATH, exp_num, order,\n",
    "                                        'ST1_p-value', norm.cdf(comparison_statistic, loc=loc_1, scale=scale_1))\n",
    "\n",
    "calculate_all_sigtest_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
