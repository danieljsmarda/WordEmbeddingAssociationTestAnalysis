{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import random\n",
    "random.seed(5)\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import get_matrices_from_term_lists, \\\n",
    "    save_pickle, open_pickle, \\\n",
    "    save_experiment_arbitrary_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Caliskan GloVe\\nglove_file = '../data/external/glove.6B/glove.6B.50d.txt'\\n_ = glove2word2vec(glove_file, '../data/interim/tmp.txt')\\nwe_model = KeyedVectors.load_word2vec_format('../data/interim/tmp.txt')\\nprint('loading done!')\\nprint(f'Total words: {len(we_model.wv.vocab)}')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'glove_840B'\n",
    "SCALERS_FILEPATH = f'../data/processed/{MODEL_NAME}_scalers.pickle'\n",
    "RESULTS_FILEPATH = f'../data/interim/{MODEL_NAME}_association_metric_exps.pickle'\n",
    "we_model = KeyedVectors.load('../data/interim/glove_840_norm', mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.090876885"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fastest version, 10000 words -> 1 minute\n",
    "# (Possible TODO) May be able to add minimal speedup with itemgetter \n",
    "# (see https://stackoverflow.com/questions/18453566/python-dictionary-get-list-of-values-for-list-of-keys)\n",
    "# to speed up creation of word matrices in get_matrices_from_term_lists\n",
    "def get_test_stat(wv_obj, X_terms, Y_terms, A_terms, B_terms):  \n",
    "    [X_mtx, Y_mtx, A_mtx, B_mtx] = get_matrices_from_term_lists(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "    cosine_sim_XA = cosine_similarity(X_mtx, A_mtx)\n",
    "    cosine_sim_XB = cosine_similarity(X_mtx, B_mtx)\n",
    "    mean_over_Xa = np.mean(cosine_sim_XA, axis=1)\n",
    "    mean_over_Xb = np.mean(cosine_sim_XB, axis=1)\n",
    "    s_for_X_words = mean_over_Xa - mean_over_Xb\n",
    "    # shape is (24,) or (|X_terms|,)\n",
    "\n",
    "    cosine_sim_YA = cosine_similarity(Y_mtx, A_mtx)\n",
    "    cosine_sim_YB = cosine_similarity(Y_mtx, B_mtx)\n",
    "    mean_over_Ya = np.mean(cosine_sim_YA, axis=1)\n",
    "    mean_over_Yb = np.mean(cosine_sim_YB, axis=1)\n",
    "    s_for_Y_words = mean_over_Ya - mean_over_Yb\n",
    "    test_stat = np.mean(s_for_X_words) - np.mean(s_for_Y_words)\n",
    "    return test_stat\n",
    "get_test_stat(we_model, X_terms, Y_terms, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:50<00:00, 90.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# This cell works too. It takes twice as long as the cell above,\n",
    "# but if we want to try to vectorize the outer loop, then \n",
    "# we will probably have to use this version\n",
    "def calculate_association_metric_for_target_word(word_vec, A_mtx, B_mtx):\n",
    "    '''Computes the association metric, s(w,A,B).\n",
    "    word_vec: 1-D word vector\n",
    "    A_mtx, B_mtx: 2-D word vector arrays'''\n",
    "    A_dot_v = np.dot(A_mtx, word_vec)\n",
    "    B_dot_v = np.dot(B_mtx, word_vec)\n",
    "    A_norms = np.multiply(np.linalg.norm(A_mtx, axis=1), np.linalg.norm(word_vec))\n",
    "    B_norms = np.multiply(np.linalg.norm(B_mtx, axis=1), np.linalg.norm(word_vec))\n",
    "    A_cosines = np.divide(A_dot_v, A_norms)\n",
    "    B_cosines = np.divide(B_dot_v, B_norms)\n",
    "    return np.mean(A_cosines) - np.mean(B_cosines)\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    [X_mtx, Y_mtx, A_mtx, B_mtx] = get_matrices_from_term_lists(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "    X_associations = np.apply_along_axis(lambda x_vec: calculate_association_metric_for_target_word(x_vec, A_mtx, B_mtx), 1, X_mtx)\n",
    "    Y_associations = np.apply_along_axis(lambda y_vec: calculate_association_metric_for_target_word(y_vec, A_mtx, B_mtx), 1, Y_mtx)\n",
    "    m = np.mean(X_associations) - np.mean(Y_associations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_test_stats(wv_obj, X_terms, Y_terms, A_terms, B_terms, n_samples=100):\n",
    "    sigtest_dist_1 = []\n",
    "    sigtest_dist_2 = []\n",
    "    sigtest_dist_3 = []\n",
    "    n_targets = len(X_terms)\n",
    "    n_attributes = len(A_terms)\n",
    "    assert len(X_terms) == len(Y_terms)\n",
    "    assert len(A_terms) == len(B_terms)\n",
    "    vocab_list = list(wv_obj.wv.vocab)\n",
    "    random.seed(5)\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        X_sample = random.sample(vocab_list, k=n_targets)\n",
    "        Y_sample = random.sample(vocab_list, k=n_targets)\n",
    "        sigtest_dist_1.append(get_test_stat(wv_obj, X_sample, Y_sample, A_terms, B_terms))\n",
    "        sigtest_dist_2.append(get_test_stat(wv_obj, X_terms, Y_sample, A_terms, B_terms))\n",
    "        sigtest_dist_3.append(get_test_stat(wv_obj, Y_terms, X_sample, A_terms, B_terms))\n",
    "        #sigtest_dist_3.append(get_test_stat(wv_obj, X_sample, Y_terms, A_terms, B_terms))\n",
    "    return np.array(sigtest_dist_1), np.array(sigtest_dist_2), np.array(sigtest_dist_3)\n",
    "#a,b,c = get_n_test_stats(we_model, X_terms, Y_terms, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER = second\n",
      "******************************\n",
      "Experiment: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Miniconda3\\envs\\semproject2\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n",
      " 19%|██████████████▊                                                              | 1916/10000 [00:44<03:09, 42.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b10a6d9eecd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mrun_exps_1storder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mrun_all_sigtests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'second'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-b10a6d9eecd0>\u001b[0m in \u001b[0;36mrun_all_sigtests\u001b[1;34m(order)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m#scaler = scalers_dict[exp_num][order]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mcomparison_statistic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mdist_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_n_test_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;31m#[dist_1, dist_2, dist_3] = [scaler.transform(dist.reshape(-1,1)).reshape(len(dist)) for dist in [dist_1, dist_2, dist_3]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
      "\u001b[1;32m<ipython-input-14-371f8ce83f36>\u001b[0m in \u001b[0;36mget_n_test_stats\u001b[1;34m(wv_obj, X_terms, Y_terms, A_terms, B_terms, n_samples)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mX_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mY_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msigtest_dist_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0msigtest_dist_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0msigtest_dist_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-3f99d379663f>\u001b[0m in \u001b[0;36mget_test_stat\u001b[1;34m(wv_obj, X_terms, Y_terms, A_terms, B_terms)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# to speed up creation of word matrices in get_matrices_from_term_lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mX_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_mtx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matrices_from_term_lists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mcosine_sim_XA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcosine_sim_XB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GRADSCHOOL\\SemesterProjects\\Navid\\GitRepos\\first-order-cooccurrence-metric-experiments\\src\\models\\effect_size.py\u001b[0m in \u001b[0;36mget_matrices_from_term_lists\u001b[1;34m(wv_obj, X_terms, Y_terms, A_terms, B_terms)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mA_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mA_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mB_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_getter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GRADSCHOOL\\SemesterProjects\\Navid\\GitRepos\\first-order-cooccurrence-metric-experiments\\src\\models\\effect_size.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mA_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mA_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mB_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_getter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\semproject2\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reminder that if you run this cell with a lower number of n_samples, \n",
    "# It will overwrite what's currently in the dictionary\n",
    "FILEPATH = '../data/interim/glove_840B_association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/glove_840B_experiment_definitions.pickle'\n",
    "'''\n",
    "FILEPATH = '../data/interim/association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/experiment_definitions.pickle'\n",
    "'''\n",
    "def run_all_sigtests(order='second'):\n",
    "    #TODO: refactor: remove 'order' argument, no longer necessary\n",
    "    exps = open_pickle(EXPERIMENT_DEFINITION_PATH)\n",
    "    scalers_dict = open_pickle(SCALERS_FILEPATH)\n",
    "    print(f'ORDER = {order}')\n",
    "    for exp_num, exp in exps.items():\n",
    "        print('******************************')\n",
    "        print(f'Experiment: {exp_num}')\n",
    "        X_terms = exp['X_terms']\n",
    "        Y_terms = exp['Y_terms']\n",
    "        A_terms = exp['A_terms']\n",
    "        B_terms = exp['B_terms']\n",
    "        #scaler = scalers_dict[exp_num][order]\n",
    "        comparison_statistic = get_test_stat(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "        dist_1, dist_2, dist_3 = get_n_test_stats(we_model, X_terms, Y_terms, A_terms, B_terms, n_samples=10000)\n",
    "        #[dist_1, dist_2, dist_3] = [scaler.transform(dist.reshape(-1,1)).reshape(len(dist)) for dist in [dist_1, dist_2, dist_3]]\n",
    "        save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                        'sigtest_dist_1', dist_1)\n",
    "        save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                        'sigtest_dist_2', dist_2)\n",
    "        save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                        'sigtest_dist_3', dist_3)\n",
    "run_all_sigtests(order='second')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILEPATH = '../data/interim/glove_840B_association_metric_exps.pickle'\n",
    "d = open_pickle(RESULTS_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'second': {'X_array': array([ 0.04218954,  0.07744247, -0.00571454,  0.05228046,  0.04121482,\n",
       "                      0.01642609,  0.05941069,  0.08293772,  0.10962468,  0.06767094,\n",
       "                      0.05554709,  0.08660334,  0.11914104,  0.02486253,  0.09582818,\n",
       "                      0.06356439,  0.10746822,  0.09457076,  0.0782218 ,  0.06955409,\n",
       "                      0.07021624,  0.00056103,  0.07109076,  0.00462493,  0.01719075],\n",
       "                    dtype=float32),\n",
       "              'Y_array': array([-0.06156641, -0.02580431, -0.01672459, -0.09525567, -0.04476053,\n",
       "                     -0.16175112, -0.07126629,  0.05551386, -0.14847207, -0.04637542,\n",
       "                      0.02886164, -0.11517835, -0.08661395, -0.07366097, -0.09728244,\n",
       "                     -0.07608503,  0.02309245, -0.10237056, -0.07108605, -0.11936021,\n",
       "                     -0.1044682 ,  0.08603638, -0.07104123, -0.0895586 , -0.11381534],\n",
       "                    dtype=float32),\n",
       "              'X_mean': 0.060101118,\n",
       "              'Y_mean': -0.063959725,\n",
       "              'threshold': 0.43816024,\n",
       "              'sigtest_dist_1': array([-0.00551653,  0.00711494, -0.001962  , ...,  0.0013866 ,\n",
       "                      0.00533939, -0.00646463], dtype=float32),\n",
       "              'sigtest_dist_2': array([0.0613047 , 0.07639948, 0.06793268, ..., 0.07333187, 0.06985791,\n",
       "                     0.06948714], dtype=float32),\n",
       "              'sigtest_dist_3': array([0.02405564, 0.02159235, 0.0209822 , ..., 0.01893162, 0.02635836,\n",
       "                     0.01492511], dtype=float32),\n",
       "              'test_statistic': 0.090876885,\n",
       "              'ST1_p-value': 1.0,\n",
       "              'CI_dict': {'QR_95': [0.29073653742671013, 0.4350595474243164],\n",
       "               'QR_99': [0.26268959045410156, 0.473987040668726],\n",
       "               'QR_99.9': [0.2061524347215891, 0.5366199171543184]}}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER = second\n",
      "******************************\n",
      "Experiment: 1\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [1][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [1][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 2\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [2][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [2][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 3\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [3][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [3][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 4\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [4][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [4][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 5\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [5][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [5][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 6\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [6][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [6][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 7\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [7][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [7][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 8\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [8][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [8][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 9\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [9][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [9][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 10\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [10][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [10][second][ST1_p-value]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "'''\n",
    "FILEPATH = '../data/interim/association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/experiment_definitions.pickle'\n",
    "'''\n",
    "FILEPATH = '../data/interim/glove_840B_association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/glove_840B_experiment_definitions.pickle'\n",
    "def calculate_all_sigtest_metrics(order='second'):\n",
    "    #TODO: refactor: remove 'order' argument, no longer necessary\n",
    "    exps = open_pickle(EXPERIMENT_DEFINITION_PATH)\n",
    "    scalers_dict = open_pickle(SCALERS_FILEPATH)\n",
    "    results_dict = open_pickle(RESULTS_FILEPATH)\n",
    "    print(f'ORDER = {order}')\n",
    "    for exp_num, exp in exps.items():\n",
    "        print('******************************')\n",
    "        print(f'Experiment: {exp_num}')\n",
    "        X_terms = exp['X_terms']\n",
    "        Y_terms = exp['Y_terms']\n",
    "        A_terms = exp['A_terms']\n",
    "        B_terms = exp['B_terms']\n",
    "        comparison_statistic = get_test_stat(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "\n",
    "        dist_1, dist_2, dist_3 = [results_dict[exp_num][order][f'sigtest_dist_{n}'] for n in [1,2,3]]\n",
    "        loc_1, loc_2, loc_3 = [np.mean(dist) for dist in [dist_1, dist_2, dist_3]]\n",
    "        scale_1, scale_2, scale_3 = [np.std(dist) for dist in [dist_1, dist_2, dist_3]]\n",
    "        # If you want to play around with statistics of the distributions,\n",
    "        # Add code and print statements here, e.g.\n",
    "        # print(f'90% CI for dist 1: {norm.ppf(0.1, loc=loc_1, scale=scale_1)}')\n",
    "\n",
    "        save_experiment_arbitrary_label(FILEPATH, exp_num, order, 'test_statistic', comparison_statistic)\n",
    "        save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                        'ST1_p-value', norm.cdf(comparison_statistic, loc=loc_1, scale=scale_1))\n",
    "\n",
    "calculate_all_sigtest_metrics(order='second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
