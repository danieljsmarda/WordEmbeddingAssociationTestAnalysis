{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import random\n",
    "random.seed(5)\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import get_matrices_from_term_lists, \\\n",
    "    filter_terms_not_in_wemodel, \\\n",
    "    save_pickle, open_pickle, \\\n",
    "    save_experiment_arbitrary_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Caliskan GloVe\\nglove_file = '../data/external/glove.6B/glove.6B.50d.txt'\\n_ = glove2word2vec(glove_file, '../data/interim/tmp.txt')\\nwe_model = KeyedVectors.load_word2vec_format('../data/interim/tmp.txt')\\nprint('loading done!')\\nprint(f'Total words: {len(we_model.wv.vocab)}')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCALERS_FILEPATH = '../data/processed/glove_840B_scalers.pickle'\n",
    "RESULTS_FILEPATH = '../data/interim/glove_840B_association_metric_exps.pickle'\n",
    "we_model = KeyedVectors.load('../data/interim/glove_840_norm', mmap='r')\n",
    "\n",
    "'''SCALERS_FILEPATH = '../data/processed/scalers.pickle'\n",
    "RESULTS_FILEPATH = '../data/interim/association_metric_exps.pickle'\n",
    "\n",
    "we_model_name = \"sg_dim300_min100_win5\"\n",
    "we_vector_size = 300\n",
    "we_model_dir = '../data/external/wiki-english/wiki-english-20171001/%s' % we_model_name\n",
    "\n",
    "we_model = Word2Vec.load(we_model_dir+'/model.gensim')\n",
    "print ('loading done!')\n",
    "print(f'Total words: {len(we_model.wv.vocab)}')\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Caliskan GloVe\n",
    "glove_file = '../data/external/glove.6B/glove.6B.50d.txt'\n",
    "_ = glove2word2vec(glove_file, '../data/interim/tmp.txt')\n",
    "we_model = KeyedVectors.load_word2vec_format('../data/interim/tmp.txt')\n",
    "print('loading done!')\n",
    "print(f'Total words: {len(we_model.wv.vocab)}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n"
     ]
    }
   ],
   "source": [
    "X_terms = ['aster', 'clover', 'hyacinth', 'marigold', 'poppy', 'azalea', \n",
    "           'crocus', 'iris', 'orchid', 'rose', 'bluebell', 'daffodil','lilac',\n",
    "           'pansy','tulip','buttercup','daisy','lily','penny','violet','carnation', 'gladiola',\n",
    "           'magnolia','petunia','zinnia']\n",
    "Y_terms = ['ant','caterpillar','flea','locust','spider','bedbug','centipede','fly',\n",
    "          'maggot','tarantula','bee','cockroach','gnat','mosquito','termite','beetle',\n",
    "          'cricket','hornet','moth','wasp','blackfly','dragonfly','horsefly','roach',\n",
    "          'weevil']\n",
    "A_terms = ['caress','freedom','health','love','peace','cheer','friend','heaven',\n",
    "           'loyal','pleasure','diamond','gentle','honest','lucky','rainbow','diploma',\n",
    "           'gift','honor','miracle','sunrise','family','happy','laugher','paradise',\n",
    "           'vacation']\n",
    "B_terms = ['abuse','crash','filth','murder','sickness','accident','death','grief',\n",
    "          'poison','stink','assault','disaster','hatred','pollute','tragedy',\n",
    "          'divorce','jail','poverty','ugly','cancer','kill','rotten','vomit','agony',\n",
    "          'prison']\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.090876885"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fastest version, 10000 words -> 1 minute\n",
    "# (Possible TODO) May be able to add minimal speedup with itemgetter \n",
    "# (see https://stackoverflow.com/questions/18453566/python-dictionary-get-list-of-values-for-list-of-keys)\n",
    "# to speed up creation of word matrices in get_matrices_from_term_lists\n",
    "def get_test_stat(wv_obj, X_terms, Y_terms, A_terms, B_terms):  \n",
    "    [X_mtx, Y_mtx, A_mtx, B_mtx] = get_matrices_from_term_lists(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "    cosine_sim_XA = cosine_similarity(X_mtx, A_mtx)\n",
    "    cosine_sim_XB = cosine_similarity(X_mtx, B_mtx)\n",
    "    mean_over_Xa = np.mean(cosine_sim_XA, axis=1)\n",
    "    mean_over_Xb = np.mean(cosine_sim_XB, axis=1)\n",
    "    s_for_X_words = mean_over_Xa - mean_over_Xb\n",
    "    # shape is (24,) or (|X_terms|,)\n",
    "\n",
    "    cosine_sim_YA = cosine_similarity(Y_mtx, A_mtx)\n",
    "    cosine_sim_YB = cosine_similarity(Y_mtx, B_mtx)\n",
    "    mean_over_Ya = np.mean(cosine_sim_YA, axis=1)\n",
    "    mean_over_Yb = np.mean(cosine_sim_YB, axis=1)\n",
    "    s_for_Y_words = mean_over_Ya - mean_over_Yb\n",
    "    test_stat = np.mean(s_for_X_words) - np.mean(s_for_Y_words)\n",
    "    return test_stat\n",
    "get_test_stat(we_model, X_terms, Y_terms, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:50<00:00, 90.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# This cell works too. It takes twice as long as the cell above,\n",
    "# but if we want to try to vectorize the outer loop, then \n",
    "# we will probably have to use this version\n",
    "def calculate_association_metric_for_target_word(word_vec, A_mtx, B_mtx):\n",
    "    '''Computes the association metric, s(w,A,B).\n",
    "    word_vec: 1-D word vector\n",
    "    A_mtx, B_mtx: 2-D word vector arrays'''\n",
    "    A_dot_v = np.dot(A_mtx, word_vec)\n",
    "    B_dot_v = np.dot(B_mtx, word_vec)\n",
    "    A_norms = np.multiply(np.linalg.norm(A_mtx, axis=1), np.linalg.norm(word_vec))\n",
    "    B_norms = np.multiply(np.linalg.norm(B_mtx, axis=1), np.linalg.norm(word_vec))\n",
    "    A_cosines = np.divide(A_dot_v, A_norms)\n",
    "    B_cosines = np.divide(B_dot_v, B_norms)\n",
    "    return np.mean(A_cosines) - np.mean(B_cosines)\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    [X_mtx, Y_mtx, A_mtx, B_mtx] = get_matrices_from_term_lists(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "    X_associations = np.apply_along_axis(lambda x_vec: calculate_association_metric_for_target_word(x_vec, A_mtx, B_mtx), 1, X_mtx)\n",
    "    Y_associations = np.apply_along_axis(lambda y_vec: calculate_association_metric_for_target_word(y_vec, A_mtx, B_mtx), 1, Y_mtx)\n",
    "    m = np.mean(X_associations) - np.mean(Y_associations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_test_stats(wv_obj, X_terms, Y_terms, A_terms, B_terms, n_samples=100):\n",
    "    sigtest_dist_1 = []\n",
    "    sigtest_dist_2 = []\n",
    "    sigtest_dist_3 = []\n",
    "    n_targets = len(X_terms)\n",
    "    n_attributes = len(A_terms)\n",
    "    assert len(X_terms) == len(Y_terms)\n",
    "    assert len(A_terms) == len(B_terms)\n",
    "    vocab_list = list(wv_obj.wv.vocab)\n",
    "    random.seed(5)\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        X_sample = random.sample(vocab_list, k=n_targets)\n",
    "        Y_sample = random.sample(vocab_list, k=n_targets)\n",
    "        sigtest_dist_1.append(get_test_stat(wv_obj, X_sample, Y_sample, A_terms, B_terms))\n",
    "        sigtest_dist_2.append(get_test_stat(wv_obj, X_terms, Y_sample, A_terms, B_terms))\n",
    "        sigtest_dist_3.append(get_test_stat(wv_obj, Y_terms, X_sample, A_terms, B_terms))\n",
    "        #sigtest_dist_3.append(get_test_stat(wv_obj, X_sample, Y_terms, A_terms, B_terms))\n",
    "    return np.array(sigtest_dist_1), np.array(sigtest_dist_2), np.array(sigtest_dist_3)\n",
    "#a,b,c = get_n_test_stats(we_model, X_terms, Y_terms, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER = second\n",
      "******************************\n",
      "Experiment: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Miniconda3\\envs\\semproject2\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n",
      " 19%|██████████████▊                                                              | 1916/10000 [00:44<03:09, 42.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b10a6d9eecd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mrun_exps_1storder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mrun_all_sigtests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'second'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-b10a6d9eecd0>\u001b[0m in \u001b[0;36mrun_all_sigtests\u001b[1;34m(order)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m#scaler = scalers_dict[exp_num][order]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mcomparison_statistic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mdist_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_n_test_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;31m#[dist_1, dist_2, dist_3] = [scaler.transform(dist.reshape(-1,1)).reshape(len(dist)) for dist in [dist_1, dist_2, dist_3]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
      "\u001b[1;32m<ipython-input-14-371f8ce83f36>\u001b[0m in \u001b[0;36mget_n_test_stats\u001b[1;34m(wv_obj, X_terms, Y_terms, A_terms, B_terms, n_samples)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mX_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mY_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msigtest_dist_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0msigtest_dist_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0msigtest_dist_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-3f99d379663f>\u001b[0m in \u001b[0;36mget_test_stat\u001b[1;34m(wv_obj, X_terms, Y_terms, A_terms, B_terms)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# to speed up creation of word matrices in get_matrices_from_term_lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_test_stat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mX_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_mtx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matrices_from_term_lists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mcosine_sim_XA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcosine_sim_XB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GRADSCHOOL\\SemesterProjects\\Navid\\GitRepos\\first-order-cooccurrence-metric-experiments\\src\\models\\effect_size.py\u001b[0m in \u001b[0;36mget_matrices_from_term_lists\u001b[1;34m(wv_obj, X_terms, Y_terms, A_terms, B_terms)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mA_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mA_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mB_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_getter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GRADSCHOOL\\SemesterProjects\\Navid\\GitRepos\\first-order-cooccurrence-metric-experiments\\src\\models\\effect_size.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mA_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mA_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mB_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mB_terms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_getter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\semproject2\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reminder that if you run this cell with a lower number of n_samples, \n",
    "# It will overwrite what's currently in the dictionary\n",
    "FILEPATH = '../data/interim/glove_840B_association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/glove_840B_experiment_definitions.pickle'\n",
    "'''\n",
    "FILEPATH = '../data/interim/association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/experiment_definitions.pickle'\n",
    "'''\n",
    "def run_all_sigtests(order='second'):\n",
    "    exps = open_pickle(EXPERIMENT_DEFINITION_PATH)\n",
    "    scalers_dict = open_pickle(SCALERS_FILEPATH)\n",
    "    print(f'ORDER = {order}')\n",
    "    for exp_num, exp in exps.items():\n",
    "        print('******************************')\n",
    "        print(f'Experiment: {exp_num}')\n",
    "        X_terms = exp['X_terms']\n",
    "        Y_terms = exp['Y_terms']\n",
    "        A_terms = exp['A_terms']\n",
    "        B_terms = exp['B_terms']\n",
    "        if order == 'second':\n",
    "            #scaler = scalers_dict[exp_num][order]\n",
    "            comparison_statistic = get_test_stat(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "            dist_1, dist_2, dist_3 = get_n_test_stats(we_model, X_terms, Y_terms, A_terms, B_terms, n_samples=10000)\n",
    "            #[dist_1, dist_2, dist_3] = [scaler.transform(dist.reshape(-1,1)).reshape(len(dist)) for dist in [dist_1, dist_2, dist_3]]\n",
    "            save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                            'sigtest_dist_1', dist_1)\n",
    "            save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                            'sigtest_dist_2', dist_2)\n",
    "            save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                            'sigtest_dist_3', dist_3)\n",
    "        else:\n",
    "            #TODO\n",
    "            raise NotImplementedError\n",
    "            run_exps_1storder(X_terms, Y_terms, A_terms, B_terms, exp_num)\n",
    "run_all_sigtests(order='second')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILEPATH = '../data/interim/glove_840B_association_metric_exps.pickle'\n",
    "d = open_pickle(RESULTS_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'first': {'X_array': array([ 0.08113076,  0.18911934, -0.0954811 ,  0.13401467,  0.09897012,\n",
       "                      0.19287561,  0.11558053,  0.06996465,  0.12096066,  0.12797187,\n",
       "                      0.11942707,  0.18256408,  0.17806363,  0.17999095,  0.11687332,\n",
       "                      0.08817419,  0.13236946,  0.10520089,  0.17782208,  0.09271343,\n",
       "                      0.14632878,  0.13019669,  0.14671066,  0.15014505], dtype=float32),\n",
       "              'Y_array': array([-0.04801004, -0.06460989, -0.08932857, -0.06297787, -0.40200305,\n",
       "                     -0.1162259 ,  0.05139589, -0.29557508, -0.14763156,  0.11352445,\n",
       "                     -0.1613886 , -0.0787251 , -0.19676779, -0.14766207, -0.03967397,\n",
       "                      0.07359396, -0.04168847,  0.08253389, -0.0736915 , -0.06181172,\n",
       "                      0.0839064 ,  0.08104831,  0.03454182, -0.13286161], dtype=float32),\n",
       "              'X_mean': 0.12423697,\n",
       "              'Y_mean': -0.068337,\n",
       "              'threshold': 0.065379,\n",
       "              'A_5': 0.01671242192387581,\n",
       "              'A_95': 0.16997475624084463,\n",
       "              'B_5': 0.00969968494027853,\n",
       "              'B_95': 0.16997475624084463,\n",
       "              'pct_5': 0,\n",
       "              'pct_95': 0},\n",
       "             'second': {'X_array': array([ 0.06463376,  0.13652503, -0.04676503,  0.11253601,  0.04916599,\n",
       "                      0.17652243,  0.09883526,  0.04855525,  0.07594025,  0.16368937,\n",
       "                      0.08388424,  0.11431959,  0.13489187,  0.08018041,  0.1137642 ,\n",
       "                      0.09362984,  0.10222384,  0.09800541,  0.14387575,  0.04530728,\n",
       "                      0.09423137,  0.14132568,  0.06971878,  0.06853676], dtype=float32),\n",
       "              'Y_array': array([-0.02787289, -0.01819867, -0.06967109, -0.01150721, -0.1667692 ,\n",
       "                     -0.06400925,  0.04445949, -0.18263587, -0.07073748,  0.11490756,\n",
       "                     -0.09649387, -0.04441088, -0.11249268, -0.08999455, -0.10317296,\n",
       "                      0.02992854,  0.0309861 , -0.02143282, -0.06515384,  0.02837816,\n",
       "                      0.04654327,  0.03567371,  0.03692234, -0.11014193], dtype=float32),\n",
       "              'X_mean': 0.09431389,\n",
       "              'Y_mean': -0.036954004,\n",
       "              'threshold': 0.0380725,\n",
       "              'pct_5': 0.006891302671283487,\n",
       "              'pct_95': 0.557002368569374,\n",
       "              'A_biases': array([0.24636367, 0.3360326 , 0.32783392, 0.34475553, 0.2964261 ,\n",
       "                     0.3219602 , 0.42715466, 0.33073768, 0.37278342, 0.42416668,\n",
       "                     0.3732654 , 0.21366799, 0.2673483 , 0.22172835, 0.2853265 ,\n",
       "                     0.36145395, 0.2938422 , 0.33583495, 0.22876093, 0.31422225,\n",
       "                     0.36241674, 0.30265492, 0.39434937, 0.28584054], dtype=float32),\n",
       "              'lower_bound': -0.12051583379507065,\n",
       "              'upper_bound': 0.10539177060127258,\n",
       "              'sigtest_dist_1': array([-0.02278844,  0.01071456, -0.02869216,  0.01714606,  0.00948824,\n",
       "                     -0.02120862, -0.00753119,  0.01627057, -0.01482924, -0.03849091,\n",
       "                     -0.037406  , -0.00594183, -0.00592028, -0.01449078,  0.00783928,\n",
       "                      0.03781715, -0.01761949, -0.02109337, -0.02240095, -0.02170147,\n",
       "                     -0.02999781, -0.02487207, -0.01689958, -0.0358322 , -0.03375135,\n",
       "                     -0.06192791, -0.05288193, -0.03577231,  0.04912531, -0.06158748,\n",
       "                     -0.02019878,  0.00941672, -0.02184662, -0.03451368, -0.03442041,\n",
       "                     -0.00083792, -0.03103763, -0.02191407, -0.00191174, -0.00167735,\n",
       "                     -0.01569331, -0.01356728,  0.03405198, -0.01739793, -0.00599407,\n",
       "                     -0.00964933, -0.02573184,  0.00537388, -0.03004614, -0.03394433,\n",
       "                     -0.01313255, -0.02314367, -0.03523306, -0.04224534,  0.02159517,\n",
       "                      0.00421176,  0.00212166, -0.00916136, -0.02309524, -0.02104329,\n",
       "                     -0.0091516 , -0.02573612,  0.00767303, -0.01372541, -0.03862743,\n",
       "                     -0.04645456, -0.00982103,  0.02084395, -0.00381894,  0.00301039,\n",
       "                     -0.0425828 , -0.00290389, -0.04691557, -0.06424466, -0.02528068,\n",
       "                     -0.04646286, -0.04414444,  0.0036796 ,  0.03369713, -0.02915087,\n",
       "                     -0.01215502, -0.03494091,  0.01000956, -0.02461507, -0.03771337,\n",
       "                     -0.01858469, -0.0154082 ,  0.01530097, -0.03749118, -0.03118071,\n",
       "                     -0.02233622, -0.0065512 , -0.00039772, -0.0222212 , -0.01167982,\n",
       "                     -0.01070824, -0.02960046, -0.04216523, -0.02389374, -0.05712013],\n",
       "                    dtype=float32),\n",
       "              'sigtest_dist_2': array([0.05322596, 0.08057187, 0.06321464, 0.076553  , 0.07042868,\n",
       "                     0.07171623, 0.05341932, 0.07686932, 0.07093902, 0.04553378,\n",
       "                     0.03570629, 0.06766267, 0.06593074, 0.07681672, 0.0691748 ,\n",
       "                     0.10779183, 0.06646325, 0.0527877 , 0.0495975 , 0.06662232,\n",
       "                     0.04624435, 0.05301303, 0.05642455, 0.05997471, 0.07097192,\n",
       "                     0.04322982, 0.0431255 , 0.05041242, 0.09557579, 0.03510886,\n",
       "                     0.04944801, 0.07461886, 0.06658114, 0.02964267, 0.06800494,\n",
       "                     0.0754392 , 0.04507708, 0.06275605, 0.06683432, 0.05578344,\n",
       "                     0.06962999, 0.05658977, 0.09268044, 0.07456292, 0.065553  ,\n",
       "                     0.05549554, 0.060634  , 0.06970958, 0.0571382 , 0.04986701,\n",
       "                     0.07255745, 0.06190804, 0.05453058, 0.04831959, 0.08426621,\n",
       "                     0.08453087, 0.05897348, 0.05283081, 0.05660336, 0.05721732,\n",
       "                     0.0459668 , 0.0733615 , 0.05089598, 0.06723727, 0.04630826,\n",
       "                     0.04921684, 0.06866928, 0.08316525, 0.06174957, 0.07039922,\n",
       "                     0.06208481, 0.05971804, 0.04836845, 0.02172274, 0.07763872,\n",
       "                     0.02574291, 0.05372776, 0.06499087, 0.0882064 , 0.04916794,\n",
       "                     0.06266312, 0.05507081, 0.07870511, 0.05742621, 0.05997261,\n",
       "                     0.05941956, 0.0781735 , 0.10101382, 0.04954731, 0.05683553,\n",
       "                     0.04531052, 0.07732385, 0.0681693 , 0.05745577, 0.08491602,\n",
       "                     0.05465241, 0.0445453 , 0.0532662 , 0.06407075, 0.03580608],\n",
       "                    dtype=float32),\n",
       "              'sigtest_dist_3': array([0.03759534, 0.04375243, 0.02170293, 0.0542028 , 0.05266929,\n",
       "                     0.02068489, 0.05265922, 0.05301099, 0.02784148, 0.02958504,\n",
       "                     0.04049744, 0.04000524, 0.04175872, 0.02230225, 0.05227423,\n",
       "                     0.04363505, 0.02952702, 0.03972867, 0.04161128, 0.02528595,\n",
       "                     0.03736758, 0.03572464, 0.04028561, 0.01780283, 0.00888647,\n",
       "                     0.00845201, 0.01760231, 0.02742501, 0.06715927, 0.01691339,\n",
       "                     0.04396296, 0.04840761, 0.02518198, 0.04945339, 0.01118439,\n",
       "                     0.03733262, 0.03749503, 0.02893962, 0.04486367, 0.05614895,\n",
       "                     0.02828643, 0.04345269, 0.05498128, 0.02164888, 0.04206267,\n",
       "                     0.04846487, 0.0272439 , 0.04927403, 0.02642541, 0.0297984 ,\n",
       "                     0.02791973, 0.02855803, 0.0238461 , 0.02304481, 0.0509387 ,\n",
       "                     0.03329063, 0.05675791, 0.05161756, 0.03391115, 0.03534912,\n",
       "                     0.05849135, 0.01451212, 0.07038679, 0.03264706, 0.02867405,\n",
       "                     0.01793833, 0.03511942, 0.05128843, 0.04804122, 0.04622091,\n",
       "                     0.00894214, 0.0509878 , 0.01832573, 0.02764234, 0.01069034,\n",
       "                     0.04140398, 0.01573754, 0.05229847, 0.05910048, 0.03529093,\n",
       "                     0.03879161, 0.02359802, 0.04491419, 0.03156846, 0.01592375,\n",
       "                     0.03560549, 0.02002804, 0.0278969 , 0.02657124, 0.02559349,\n",
       "                     0.045963  , 0.0297347 , 0.04504272, 0.03393277, 0.0170139 ,\n",
       "                     0.04824909, 0.03946397, 0.01817831, 0.02564524, 0.02068353],\n",
       "                    dtype=float32)}})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER = second\n",
      "******************************\n",
      "Experiment: 1\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [1][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [1][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 2\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [2][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [2][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 3\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [3][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [3][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 4\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [4][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [4][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 5\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [5][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [5][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 6\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [6][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [6][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 7\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [7][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [7][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 8\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [8][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [8][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 9\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [9][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [9][second][ST1_p-value]\n",
      "******************************\n",
      "Experiment: 10\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [10][second][test_statistic]\n",
      "Results array successfully saved to file ../data/interim/glove_840B_association_metric_exps.pickle under    keys [10][second][ST1_p-value]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "'''\n",
    "FILEPATH = '../data/interim/association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/experiment_definitions.pickle'\n",
    "'''\n",
    "FILEPATH = '../data/interim/glove_840B_association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/glove_840B_experiment_definitions.pickle'\n",
    "def calculate_all_sigtest_metrics(order='second'):\n",
    "    exps = open_pickle(EXPERIMENT_DEFINITION_PATH)\n",
    "    scalers_dict = open_pickle(SCALERS_FILEPATH)\n",
    "    results_dict = open_pickle(RESULTS_FILEPATH)\n",
    "    print(f'ORDER = {order}')\n",
    "    for exp_num, exp in exps.items():\n",
    "        print('******************************')\n",
    "        print(f'Experiment: {exp_num}')\n",
    "        X_terms = exp['X_terms']\n",
    "        Y_terms = exp['Y_terms']\n",
    "        A_terms = exp['A_terms']\n",
    "        B_terms = exp['B_terms']\n",
    "        if order == 'second':\n",
    "            comparison_statistic = get_test_stat(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "            \n",
    "            dist_1, dist_2, dist_3 = [results_dict[exp_num][order][f'sigtest_dist_{n}'] for n in [1,2,3]]\n",
    "            loc_1, loc_2, loc_3 = [np.mean(dist) for dist in [dist_1, dist_2, dist_3]]\n",
    "            scale_1, scale_2, scale_3 = [np.std(dist) for dist in [dist_1, dist_2, dist_3]]\n",
    "            # If you want to play around with statistics of the distributions,\n",
    "            # Add code and print statements here, e.g.\n",
    "            # print(f'90% CI for dist 1: {norm.ppf(0.1, loc=loc_1, scale=scale_1)}')\n",
    "            \n",
    "            save_experiment_arbitrary_label(FILEPATH, exp_num, order, 'test_statistic', comparison_statistic)\n",
    "            save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                            'ST1_p-value', norm.cdf(comparison_statistic, loc=loc_1, scale=scale_1))\n",
    "            \n",
    "        else:\n",
    "            #TODO\n",
    "            raise NotImplementedError\n",
    "            run_exps_1storder(X_terms, Y_terms, A_terms, B_terms, exp_num)\n",
    "calculate_all_sigtest_metrics(order='second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
